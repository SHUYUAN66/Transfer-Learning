{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style=\"color:red\">SuAVE Transfer Learning Model</span></h1>\n",
    "\n",
    "\n",
    "For a simple Python implementation see https://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python/\n",
    "\n",
    "The model was originally described in http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Disable autoscroll and retrieve survey parameters from the URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "function getQueryStringValue (key)\n",
       "{  \n",
       "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
       "}\n",
       "IPython.notebook.kernel.execute(\"survey_url='\".concat(getQueryStringValue(\"surveyurl\")).concat(\"'\"));\n",
       "IPython.notebook.kernel.execute(\"views='\".concat(getQueryStringValue(\"views\")).concat(\"'\"));\n",
       "IPython.notebook.kernel.execute(\"view='\".concat(getQueryStringValue(\"view\")).concat(\"'\"));\n",
       "IPython.notebook.kernel.execute(\"user='\".concat(getQueryStringValue(\"user\")).concat(\"'\"));\n",
       "IPython.notebook.kernel.execute(\"csv_file='\".concat(getQueryStringValue(\"csv\")).concat(\"'\")); \n",
       "IPython.notebook.kernel.execute(\"dzc_file='\".concat(getQueryStringValue(\"dzc\")).concat(\"'\")); \n",
       "IPython.notebook.kernel.execute(\"params='\".concat(getQueryStringValue(\"params\")).concat(\"'\")); \n",
       "IPython.notebook.kernel.execute(\"active_object='\".concat(getQueryStringValue(\"activeobject\")).concat(\"'\")); \n",
       "IPython.notebook.kernel.execute(\"full_notebook_url='\" + window.location + \"'\"); \n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "function getQueryStringValue (key)\n",
    "{  \n",
    "    return unescape(window.location.search.replace(new RegExp(\"^(?:.*[&\\\\?]\" + escape(key).replace(/[\\.\\+\\*]/g, \"\\\\$&\") + \"(?:\\\\=([^&]*))?)?.*$\", \"i\"), \"$1\"));\n",
    "}\n",
    "IPython.notebook.kernel.execute(\"survey_url='\".concat(getQueryStringValue(\"surveyurl\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"views='\".concat(getQueryStringValue(\"views\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"view='\".concat(getQueryStringValue(\"view\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"user='\".concat(getQueryStringValue(\"user\")).concat(\"'\"));\n",
    "IPython.notebook.kernel.execute(\"csv_file='\".concat(getQueryStringValue(\"csv\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"dzc_file='\".concat(getQueryStringValue(\"dzc\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"params='\".concat(getQueryStringValue(\"params\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"active_object='\".concat(getQueryStringValue(\"activeobject\")).concat(\"'\")); \n",
    "IPython.notebook.kernel.execute(\"full_notebook_url='\" + window.location + \"'\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import all packages (this might take a few seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import widget functionality\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\"\n",
    "# import the necessary packages\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras import backend as K\n",
    "# import local lenet.py file describing the LeNet implementation with RELU activation functions\n",
    "#from lenet import LeNet\n",
    "\n",
    "# More imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# import the necessary packages for SVM predictor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import imutils\n",
    "\n",
    "\n",
    "# copy from sample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "# for vgg\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "# mobilenet\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initializing the number of times the model will loop and its batch size for learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f7b45fdafd448093293b9acbaf22e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='epoch_count', options=OrderedDict([('5 Iterations', 5), ('15 Itera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "epochCount = OrderedDict()\n",
    "epochCount['5 Iterations'] = 5\n",
    "epochCount['15 Iterations'] = 15\n",
    "epochCount['25 Iterations'] = 25\n",
    "\n",
    "def f(epoch_count):\n",
    "    return epoch_count\n",
    "\n",
    "epochNum = interact(f, epoch_count=epochCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a28df3c18546189d20bcd8cc2810a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='batch_size', options=OrderedDict([('32 Batch Size', 32), ('64 Batc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batchS = OrderedDict()\n",
    "batchS['32 Batch Size'] = 32\n",
    "batchS['64 Batch Size'] = 64\n",
    "batchS['128 Batch Size'] = 128\n",
    "\n",
    "def f(batch_size):\n",
    "    return batch_size\n",
    "\n",
    "batchNum = interact(f, batch_size=batchS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the number of epochs to train for, init learning rate and batch size\n",
    "EPOCHS = epochNum.widget.result\n",
    "INIT_LR = 1e-3\n",
    "BS = batchNum.widget.result\n",
    "# init the image suffix, yset, and image list\n",
    "suffix = '.png'\n",
    "img_list = []\n",
    "yset = []\n",
    "# create labels list and 2 dicts for 2 way mapping\n",
    "labels = []\n",
    "# key = label value = number\n",
    "label_yval = dict()\n",
    "# key = number value = label\n",
    "yval_label = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load the data and choose the column name to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3134efbf81459689c187cef3102e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='predictions_menu', options=OrderedDict([('PPL/XP', 'PPL/XP'), ('An…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use csv file to grab images/labels\n",
    "absolutePath = \"../../temp_csvs/\"\n",
    "# read the csv file\n",
    "file = open(absolutePath + csv_file, encoding=\"latin-1\")\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "#generate image path\n",
    "localdzc = dzc_file.replace(\"https://maxim.ucsd.edu/dzgen/lib-staging-uploads\",\"/lib-nfs/dzgen\")\n",
    "full_images_location = localdzc.replace(\"/content.dzc\",\"/full_images/\")\n",
    "\n",
    "\n",
    "# Choose column of label for prediction\n",
    "toPredict = list(df.columns.values)\n",
    "\n",
    "pred_menu = OrderedDict()\n",
    "for i in range(0, len(toPredict)):\n",
    "    pred_menu[toPredict[i]] = toPredict[i]\n",
    "\n",
    "def f(predictions_menu):\n",
    "    return predictions_menu\n",
    "# choose which label for predictions\n",
    "out2 = interact(f, predictions_menu=pred_menu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Select pixel resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39fc58b4ca2442c7964ae9e857d2571f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=60, description='Size, pixels:', max=300, min=20, step=10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = widgets.IntSlider(value=60,min=20,max=300,step=10,description='Size, pixels:')\n",
    "display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2><span style='color:red'>Verify model parameters:</span></h2>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b>Variable to predict:  Petrographic Fabric</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b>Pixel resolution:  60</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b>Path to images:  /lib-nfs/dzgen/4d862392cf30aa7d520443c52b0599d2/full_images/</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b>Number of epochs:  5</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<b>Batch size:  32</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd(\"<h2><span style='color:red'>Verify model parameters:</span></h2>\")\n",
    "printmd(\"<b>Variable to predict:  \" +out2.widget.result + \"</b>\")\n",
    "printmd(\"<b>Pixel resolution:  \" +str(a.value) + \"</b>\")\n",
    "printmd(\"<b>Path to images:  \" +full_images_location + \"</b>\")\n",
    "printmd(\"<b>Number of epochs:  \" + str(EPOCHS) + \"</b>\")\n",
    "printmd(\"<b>Batch size:  \" +str(BS) + \"</b>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Grab the images and configure them for predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This might take a little while depending on the size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a344ccf83824429aba8c69952a5044ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='0% images loaded')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im_dimension = a.value\n",
    "# grab chosen column names\n",
    "nameCol = df['#img']\n",
    "predCol = df[out2.widget.result]\n",
    "\n",
    "def matchImage(curr_image_array, image_list):\n",
    "    for i in range(0, len(image_list)):\n",
    "        if (np.array_equal(curr_image_array, image_list[i])):\n",
    "            return i\n",
    "    \n",
    "labels = []\n",
    "# add all fabric columns to the y set\n",
    "for i in range (0,len(predCol)):\n",
    "    labels.append(predCol[i])\n",
    "\n",
    "# grab all unique labels\n",
    "uni_labels = set(labels)\n",
    "uni_labels = list(uni_labels)\n",
    "\n",
    "# assign each label a dict key number\n",
    "for i in range(0,len(uni_labels)):\n",
    "    yval_label[i] = uni_labels[i]\n",
    "    label_yval[uni_labels[i]] = i\n",
    "\n",
    "\n",
    "yset = []    \n",
    "# create list of keys associated with their labels\n",
    "for i in range (0, len(labels)):\n",
    "    yset.append(label_yval[labels[i]])\n",
    "\n",
    "file_lst=[]\n",
    "\n",
    "counter = 0\n",
    "im_count = widgets.Label(value=\"0% images loaded\")\n",
    "display(im_count)\n",
    "numfiles = len(nameCol)\n",
    "\n",
    "# gather images from path created from file names in csv file\n",
    "for i in range (0,len(nameCol)):\n",
    "    base_filename = nameCol[i]\n",
    "\n",
    "    fileName = os.path.join(full_images_location, base_filename + suffix)\n",
    "    \n",
    "    file_lst.append(fileName)\n",
    "    \n",
    "    \n",
    "    counter += 1\n",
    "    im_count.value = str(int(counter / numfiles * 100)) + \"% images loaded\"\n",
    "\n",
    "ndf=pd.DataFrame()\n",
    "ndf['id']=file_lst\n",
    "ndf['label']=list(map(str, yset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if classes >=5\n",
    "if len(np.unique(ndf['label']))>=5:\n",
    "    main_class=ndf.groupby('label').count().reset_index().sort_values('id',ascending=False).reset_index(drop=True).loc[:4,'label'].to_list()\n",
    "else:\n",
    "    main_class=list(np.unique(ndf['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['21', '17', '1', '7', '20']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty=pd.DataFrame(columns=['id','label'])\n",
    "for i in main_class:\n",
    "    n=ndf.loc[ndf['label']==i]\n",
    "    empty=pd.concat([empty,n])\n",
    "empty = empty.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 165 validated image filenames belonging to 5 classes.\n",
      "Found 55 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1/255., validation_split=0.25)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(dataframe=empty, \n",
    "                                             x_col='id',\n",
    "                                             y_col='label',\n",
    "                                             target_size=(224,224),\n",
    "                                             classes=main_class,\n",
    "                                              subset='training',\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=BS,\n",
    "                                                 class_mode='categorical',\n",
    "                                              \n",
    "                                                 shuffle=True)\n",
    " \n",
    "validation_generator = datagen.flow_from_dataframe(dataframe=empty, \n",
    "                                             x_col='id',\n",
    "                                             y_col='label',\n",
    "                                             target_size=(224,224),\n",
    "                                             classes= main_class,\n",
    "                                                subset='validation',\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=BS,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_generator.class_indices)\n",
    "train_steps = train_generator.n//train_generator.batch_size\n",
    "validation_steps = validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trytry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resnet\n",
    "base_model=ResNet50(weights='imagenet',include_top=False)\n",
    "\n",
    "newOutput=base_model.output\n",
    "newOutput=GlobalAveragePooling2D()(newOutput)\n",
    "newOutput=Dense(1024,activation='relu')(newOutput) \n",
    "newOutput=Dense(1024,activation='relu')(newOutput) \n",
    "newOutput=Dense(512,activation='relu')(newOutput)\n",
    "\n",
    "preds=Dense(num_classes,activation='softmax')(newOutput)\n",
    "\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss='binary_crossentropy',optimizer = opt,metrics=['accuracy'])\n",
    "\n",
    "#history = model.fit_generator(train_generator,steps_per_epoch=train_steps, epochs=5,\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-7d70fd27af15>:4: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 234s 47s/step - loss: 0.8665 - accuracy: 0.3233 - val_loss: 4.7928 - val_accuracy: 0.2188\n",
      "Epoch 2/5\n",
      "3/5 [=================>............] - ETA: 45s - loss: 0.5481 - accuracy: 0.5797"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,steps_per_epoch=train_steps,\n",
    "                              validation_data= validation_generator, \n",
    "                              validation_steps=validation_steps, \n",
    "                              epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "newOutput=base_model.output\n",
    "newOutput=GlobalAveragePooling2D()(newOutput)\n",
    "newOutput=Dense(1024,activation='relu')(newOutput) \n",
    "newOutput=Dense(1024,activation='relu')(newOutput) \n",
    "newOutput=Dense(512,activation='relu')(newOutput)\n",
    "preds=Dense(num_classes,activation='softmax')(newOutput)\n",
    "\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True\n",
    "history=model.fit_generator(generator=train_generator,\n",
    "                    validation_data= validation_generator, validation_steps=validation_steps,\n",
    "                   steps_per_epoch=train_steps,\n",
    "                   epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 \n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "base_model = VGG19(weights='imagenet' , include_top=False)\n",
    "newOutput=base_model.output\n",
    "newOutput=GlobalAveragePooling2D()(newOutput)\n",
    "newOutput=Dense(1024,activation='relu')(newOutput) \n",
    "newOutput=Dense(1024,activation='relu')(newOutput) \n",
    "newOutput=Dense(512,activation='relu')(newOutput)\n",
    "\n",
    "preds=Dense(num_classes,activation='softmax')(newOutput)\n",
    "\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[5:]:\n",
    "    layer.trainable=True\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history=model.fit_generator(generator=train_generator,\n",
    "                    validation_data= validation_generator, validation_steps=validation_steps,\n",
    "                   steps_per_epoch=train_steps,\n",
    "                   epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from keras.constraints import unit_norm\n",
    "base_model = VGG19(weights='imagenet' , include_top=False)\n",
    "newOutput=base_model.output\n",
    "newOutput=GlobalAveragePooling2D()(newOutput)\n",
    "newOutput=Dense(1024,activation='relu',kernel_constraint=unit_norm())(newOutput) \n",
    "newOutput=Dense(1024,activation='relu',kernel_constraint=unit_norm())(newOutput) \n",
    "newOutput=Dense(512,activation='relu',kernel_constraint=unit_norm())(newOutput)\n",
    "\n",
    "preds=Dense(num_classes,activation='softmax')(newOutput)\n",
    "\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[5:]:\n",
    "    layer.trainable=True\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history=model.fit_generator(generator=train_generator,\n",
    "                    validation_data= validation_generator, validation_steps=validation_steps,\n",
    "                   steps_per_epoch=train_steps,\n",
    "                   epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "newOutput=base_model.output\n",
    "newOutput=GlobalAveragePooling2D()(newOutput)\n",
    "newOutput=Dense(1024,activation='relu')(newOutput) \n",
    "newOutput=Dense(1024,activation='relu')(newOutput) \n",
    "newOutput=Dense(512,activation='relu')(newOutput)\n",
    "\n",
    "preds=Dense(num_classes,activation='softmax')(newOutput)\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history=model.fit_generator(generator=train_generator,\n",
    "                    validation_data= validation_generator, validation_steps=validation_steps,\n",
    "                   steps_per_epoch=train_steps,\n",
    "                   epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"model accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenet\n",
    "base_model=MobileNet(weights='imagenet',include_top=False) \n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) \n",
    "x=Dense(1024,activation='relu')(x) \n",
    "x=Dense(512,activation='relu')(x) \n",
    "preds=Dense(num_classes,activation='softmax')(x)\n",
    "model=Model(inputs=base_model.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit_generator(train_generator,steps_per_epoch=train_steps,\n",
    "                              validation_data= validation_generator, \n",
    "                              validation_steps=validation_steps, \n",
    "                              epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if every layers is trainable: there will be overfitting\n",
    "from keras.constraints import unit_norm\n",
    "base_model=MobileNet(weights='imagenet',include_top=False) \n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) \n",
    "x=Dense(1024,activation='relu')(x) \n",
    "x=Dense(512,activation='relu')(x) \n",
    "preds=Dense(num_classes,activation='softmax')(x)\n",
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "for layer in model.layers[:20]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[20:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "history = model.fit_generator(train_generator,steps_per_epoch=train_steps,\n",
    "                              validation_data= validation_generator, \n",
    "                              validation_steps=validation_steps, \n",
    "                              epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,steps_per_epoch=train_steps,\n",
    "                              validation_data= validation_generator, \n",
    "                              validation_steps=validation_steps, \n",
    "                              epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,steps_per_epoch=train_steps,\n",
    "                              validation_data= validation_generator, \n",
    "                              validation_steps=validation_steps, \n",
    "                              epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train the predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is relative to the size of the data set and the compute resources you use. May take from minutes to hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,steps_per_epoch=train_steps,\n",
    "                              validation_data= validation_generator, \n",
    "                              validation_steps=validation_steps, \n",
    "                              epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Take the original data and predict based on the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape original input data images for predicting\n",
    "img_check=datagen.flow_from_dataframe(dataframe=ndf, \n",
    "                                             x_col='id',\n",
    "                                             y_col='label',\n",
    "                                             target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=BS,\n",
    "                                                 class_mode='categorical',\n",
    "                                              \n",
    "                                                 shuffle=True)\n",
    "\n",
    "predictionsMade = []\n",
    "preds = model.predict(img_check)\n",
    "prediction_confidence = []\n",
    "for i in range(0, len(preds)):\n",
    "    prediction_confidence.append(np.amax(preds[i]))   \n",
    "\n",
    "\n",
    "\n",
    "# Run all data through the prediction model that was created\n",
    "for i in range (0,len(img_check)):\n",
    "    predIndex = np.where(preds[i] == np.amax(preds[i]))\n",
    "    prediction = int(predIndex[0][0])\n",
    "    predictionsMade.append(prediction)\n",
    "\n",
    "print(prediction_confidence)    \n",
    "# Count how many correct predictions were made\n",
    "correct = 0\n",
    "for i in range (0,len(predictionsMade)):\n",
    "    if(predictionsMade[i] == yset[i]):\n",
    "        correct += 1 \n",
    "        \n",
    "printmd(\"<b><span style='color:red'>Accuracy: \" + str(correct/len(yset)) + \"</span></b>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save the model file under models/, and reload it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate model file and save\n",
    "modelName = user + \"_cnn_\" + out2.widget.result + \"_\" + str(epochNum.widget.result) + \"_\" + str(batchNum.widget.result) + \".h5\"\n",
    "modelPath = \"models/\"\n",
    "if not os.path.exists(modelPath):\n",
    "    os.makedirs(modelPath)\n",
    "model.save(os.path.join(modelPath, modelName))\n",
    "#Load model\n",
    "from keras.models import load_model\n",
    "model2 = load_model(os.path.join(modelPath, modelName))\n",
    "printmd(\"<b><span style='color:red'>Model saved</span></b>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Enter a new header for the prediction column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate back to original csv label names\n",
    "finalPred = []\n",
    "for i in range (0,len(predictionsMade)):\n",
    "    finalPred.append(yval_label[predictionsMade[i]])\n",
    "\n",
    "from IPython.display import display\n",
    "input_text = widgets.Text(\n",
    "    value=\"predicted \" + out2.widget.result,\n",
    "    placeholder='Type label here',\n",
    "    disabled=False\n",
    ")\n",
    "output_text = widgets.Text(\n",
    "    value=\"predicted \" + out2.widget.result,\n",
    "    placeholder='New Header will be displayed here',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def bind_input_to_output(sender):\n",
    "    output_text.value = input_text.value\n",
    "\n",
    "input_text.observe(bind_input_to_output)\n",
    "\n",
    "print(\"Input new column Header Label: \")\n",
    "\n",
    "display(input_text)\n",
    "display(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Save the new version of CSV file, and give a name to new survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the new column w/ it's new column name\n",
    "pred_conf_col = \"pred_conf \" + input_text.value\n",
    "test_train_col = \"test_train \" + input_text.value\n",
    "\n",
    "df[input_text.value] = finalPred\n",
    "df[pred_conf_col] = prediction_confidence\n",
    "df[test_train_col] = test_train_list\n",
    "\n",
    "print(input_text.value)\n",
    "\n",
    "new_file = absolutePath + csv_file[:-4]+'_v1.csv'\n",
    "printmd(\"<b><span style='color:red'>A new temporary file will be created at: </span></b>\")\n",
    "print(new_file)\n",
    "df.to_csv(new_file, index=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input survey name\n",
    "\n",
    "default_name = csv_file.split(\".\")[0] + \"_\" + str(EPOCHS) + \"_\" + str(BS) + \"_\" + str(im_dimension)\n",
    "\n",
    "from IPython.display import display\n",
    "input_text = widgets.Text(value=default_name)\n",
    "output_text = widgets.Text(value=default_name)\n",
    "\n",
    "def bind_input_to_output(sender):\n",
    "    output_text.value = input_text.value\n",
    "\n",
    "# Tell the text input widget to call bind_input_to_output() on submit\n",
    "input_text.on_submit(bind_input_to_output)\n",
    "\n",
    "printmd(\"<b><span style='color:red'>Input survey name here, press Enter, and then run the next cell:</span></b>\")\n",
    "# Display input text box widget for input\n",
    "display(input_text)\n",
    "\n",
    "display(output_text)\n",
    "\n",
    "survey_name = output_text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print survey name\n",
    "survey_name = output_text.value\n",
    "printmd(\"<b><span style='color:red'>Survey Name is: </span></b>\" + survey_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Generate the survey and create survey URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "referer = survey_url.split(\"/main\")[0] +\"/\"\n",
    "upload_url = referer + \"uploadCSV\"\n",
    "new_survey_url_base = survey_url.split(user)[0]\n",
    "\n",
    "import requests\n",
    "import re\n",
    "csv = {\"file\": open(new_file, \"rb\")}\n",
    "upload_data = {\n",
    "    'name': input_text.value,\n",
    "    'dzc': dzc_file,\n",
    "    'user':user\n",
    "}\n",
    "headers = {\n",
    "    'User-Agent': 'suave user agent',\n",
    "    'referer': referer\n",
    "}\n",
    "\n",
    "r = requests.post(upload_url, files=csv, data=upload_data, headers=headers)\n",
    "\n",
    "if r.status_code == 200:\n",
    "    printmd(\"<b><span style='color:red'>New survey created successfully</span></b>\")\n",
    "    regex = re.compile('[^0-9a-zA-Z_]')\n",
    "    s_url = survey_name\n",
    "    s_url =  regex.sub('_', s_url)\n",
    "\n",
    "    url = new_survey_url_base + user + \"_\" + s_url + \".csv\" + \"&views=\" + views + \"&view=\" + view\n",
    "    print(url)\n",
    "    printmd(\"<b><span style='color:red'>Click the URL to open the new survey</span></b>\")\n",
    "else:\n",
    "    printmd(\"<b><span style='color:red'>Error creating new survey. Check if a survey with this name already exists.</span></b>\")\n",
    "    printmd(\"<b><span style='color:red'>Reason: </span></b>\"+ str(r.status_code) + \" \" + r.reason)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
